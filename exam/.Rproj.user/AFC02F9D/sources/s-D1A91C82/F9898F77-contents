---
title: "ex4"
author: '20474862'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#stringr is a library with pattern matching functions. These recognise four engines of pattern description. The most common is regular expressions. 
library(stringr)
#dplyr is a fast, consistent tool for working with data frame like objects, both in memory and out of memory.
library(dplyr)
#ggplot is a system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.
library(ggplot2)
#An evolution of 'reshape2'. It's designed specifically for data tidying (not general reshaping or aggregating) and works well with 'dplyr' data pipelines.
library(tidyr)

```


##The extra 24 hours i choose to add are from monday 9am (29.7) to tuesday at 9am.
##My start time waws thursday at 9am, cross weekend so in total, 120 hours untill tuesday 9am.

###1. Reading the file


In this excercise, we have been examining trends in road accidents in recent years. We are investigating a file of all the accidents reported to the Central Bureau for the past five years (2103-2018). The file was compiled from two different sources: Accidents reported to the police, and accidents File was arranged by Anyway, and we kindly cooperate with them. The file has about 32 thousand accidents.
In order to read the file correctly, we can use read.csv with UTF-8 Encoding

```{r readfile, echo=TRUE}
#Set the seed of R‘s random number generator, which is useful for creating simulations or random objects that can be reproduced.
set.seed(23)
#reading the file with UTF-8 encoding
accidents = read.csv("accidents.csv", encoding = "UTF-8")
```

For start, let's have a look on our data, and this time we look carefully if the hebrew values are written correctly.
```{r, echo=TRUE}
#peek the first rows of our data
head(accidents, 1)
```

Now that we had a look on our data, let's start !




###2. Reading and re-arranging the data.
####2.1.Duplicated id's:

Some id's of our data are duplicated.

**2.1.1. How many of them ?**
The duplicated() R function returns a boolean vector of duplicated values. If a column holds a value more than one time, the value will be marked as "TRUE" (starts from the second time it appears and on). To answer the question, we can sum up the number of "TRUE" values.
```{r}
#sum the duplications in id columns
sum(duplicated(accidents$id))
```
We can see that there are 33 duplications. 
*Note: By how i understand the question, if a value appears more than two times, we count it as two different duplications. If you meant otherwise, I believe the following answers meet such a requirement.*

**2.1.2. What is the maximum amount of duplications?**
To give an elegnat solution to this question, We can create a table of all the duplicated values, and the amount of times each appears in our data. To do so we will use the table() R function.

```{r}
#create a table of the number of duplicated id's
table(accidents$id[which(duplicated(accidents$id))])
#What is the maximum value ?
max(table(accidents$id[which(duplicated(accidents$id))]))
```
We can see that every id of the duplicated values is duplicated only 1 time. In other words, every one of them appears 2 times in our data, So the maximum duplications amount is 1.


**2.1.3. create a new table without the duplications.**
Let's create a new table, without the duplications.
```{r}
#remove the indices of rows that are duplicated 
accidents.new = accidents[-which(duplicated((accidents$id))),]
#X was redundant, so i will use it for counting. explained later.
accidents.new$X = 1
```


####2.2 accident_hour

**2.2.1. Create a function that verifies that each record is of the form hh: mm-hh: mm, and that the range includes exactly 15 minutes. The function should return TRUE with a valid value and FALSE otherwise.**

To check the if every hour is of the shape "hh:mm-hh:mm" we can use the str_detect function from stringr library.
Further more, to check if the time is legal (15 minutes period exactly), we will use the base functions strptime and difftime.

After checking the values in the accident_hour column, we can see that it is not crossing days. That means that there is no situation as "23:50-00:05", for example. This is an important information that will make our function more simple.
```{r, echo=TRUE}
time_verify <- function(record){
  #magic number variable
  FIFTEEN_MINUTES = 15
  #a regex to find if time is from the wanted pattern
  time_pattern = "^(([0-1][0-9]|2[0-3]):[0-5][0-9])-(([0-1][0-9]|2[0-3]):[0-5][0-9]$)"
  #if time from correct pattern
  if(str_detect(record, time_pattern)){
    #split for the two times
    time_lst = str_split(record,"-",2,TRUE)
    #using strptime R function to get the the string as time
    earlier = strptime(time_lst[1], "%H:%M")
    later = strptime(time_lst[2], "%H:%M")
    #use the difftime R function to check if time is fifteen minutes
    #since we include the last minute but arithmetics calculation is not, we add an extra minute.
    return(as.numeric(difftime(later, earlier, units = c("mins")))+1==FIFTEEN_MINUTES)
  }
    #if time not from correct pattern
  else{
    return(FALSE)
  }  
}
```

now we can check the correctens of our function, using saaply (we will save only the rows who didn't pass the function filter):
```{r, echo=TRUE}
#show the rows that aren't passing the correctness filter
check = accidents.new[which(!sapply(accidents.new$accident_hour, time_verify)),]
#remove hashtag to enable the following row
#View(accidents.new)
```

After a quick check, we can see that all the non-empty values of the hours differences in our check table are not 15 minutes.

**2.2.2. Create 2 new columns in the table, for the hour and minute, from the accident_hour column. If the record is not correct, fill in NA.**

Again, we will use regex pattern, this time with the function "str_match".
As mentioned at the forum, we will insert the first hour.
```{r,echo=TRUE}
#for each row index
for(i in (1:nrow(accidents.new))){
  #pattern spliting
  hour_str = str_match(accidents.new[i,"accident_hour"],"([0-1][0-9]|2[0-3]):([0-5][0-9])-([0-1][0-9]|2[0-3]):([0-5][0-9]$)")
  #if the time is correct by the rules of the previous question, add the hour and minutes to a new column
  if (time_verify(accidents.new[i, "accident_hour"])){
    accidents.new[i,"hour"] = hour_str[2]
    accidents.new[i,"minutes"] = hour_str[3]
  }
  else{
        accidents.new[i,"hour"] = NA
    accidents.new[i,"minutes"] = NA
  }
}
#reorder the columns so the new columns will be right after the hours
accidents.new = cbind(accidents.new[,1:64],accidents.new$hour, accidents.new$minutes,accidents.new[,65:68])
#change the colnames for the right record
colnames(accidents.new)[65:66] = c("hour","minutes")
```

**Print for the first 10 non NA records the hour and minute.**
```{r}
accidents.new[c(45:54),which(colnames(accidents.new) %in% c("accident_hour", "hour", "minutes"))]
```
###3. Accidents according to severity level.
The accident_severity variable encodes accident severity. An accident is said to be "serious" if it is severe or fatal.

**3.1. Draw a graph comparing the number of serious accidents by year (use a bar graph or lines). What You See?**

First, we need to filter the serious accidents to a new dataframe.
```{r, echo=TRUE}
#create a vector of the values we need
serious_values = c("קשה","קטלנית")
#filter by that vector
serious_accidents = accidents.new[which(accidents.new$accident_severity %in% serious_values),]
```

Now, we can use again the table() function to see how many values we have of each year.

```{r}
#make a table of the data
table(serious_accidents$accident_year)
```
I wanted to draw a graph that is comparing the serious accidenrs per year, but still without losing any information wether the accident was severe(Kasha) or fatal(Katlanit).

A nice solution in that case will be a stacked group bar plot. We can use geom_histogram with fill to do so.
    

```{r}
serious_accidents$X = 1
#a stacked bar plot
#create a totals table helper for the lables of the ggplot
totals <- serious_accidents %>% group_by(accident_year) %>% summarize(total = sum(X))

#create a ggplot and a gghistogram
g = ggplot(serious_accidents, aes(x=accident_year, fill=accident_severity)) +
  geom_histogram(bins=11) +  scale_x_continuous("Year", labels = as.character(serious_accidents$accident_year), breaks =serious_accidents$accident_year)

#print the plot with lables and additions
g + theme(axis.text.x = element_text(angle=0, vjust=1)) + ggtitle("Serious Accidents Per Year") + guides(fill=guide_legend(title="Severity")) +  
  #the white lables of groups
  geom_text(stat='count', aes(label=..count..), colour = "white", position = position_stack(vjust = 0.5), size=4)+ 
#the black sum lables  
geom_text(aes(accident_year, total + 10, label = total, fill = NULL), size = 5, data = totals)


```

What we see is that although the number of serious accidents is on the rise between 2013 and 2016, the number of fatal accidents is decreasing. In 2017 there is a significant jump in the number of serious accidents, and in 2018 the number of fatal accidents compared to previous years.


**3.2. Can the trend be explained by a change in accidents with pedestrians? Share the accidents with pedestrians and those without. What kind of accident is the trend in?**

To split the graph into two parts, first we need to add a new variable that will help us split by pedestrian involvment. Secondly, we will summerize (again, using dplyr) the pedestrians data we need. Finally, we will print the plot, using the markdown settings to show it big enough to understand. 

```{r}
#add split variable 
serious_accidents[,"pedestrian_involved"] =  ifelse(serious_accidents$accident_type_hebrew == "פגיעה בהולך רגל","Pedestrian Involved","No Pedestrians Involved")

#create the pedestrians data frame
pedestrians <- serious_accidents %>% group_by(accident_year,accident_severity, pedestrian_involved) %>% summarize(total = sum(X))

#create the ggplot
p = ggplot(pedestrians, aes(x=accident_year,y=total, fill=accident_severity)) +  geom_bar(stat = "identity", position = "dodge") +
  #split by pedestrians involvment and scaling axis
  facet_wrap(.~pedestrian_involved) + scale_x_continuous("Year", labels = as.character(pedestrians$accident_year), breaks =pedestrians$accident_year) + scale_y_continuous("Year") + 
  #designing the graph a bit
  theme(title = element_text(size=20), strip.text = element_text(size=15, color="grey3"), axis.text = element_text(size =15), axis.title = element_text(size=15), legend.text=element_text(size=15))+ 
  
  geom_text(aes(label=total), vjust=-0.5, color="black",
            position = position_dodge(1), size=4) + theme(axis.text.x = element_text(angle=0, vjust=1)) + ggtitle("Serious Accidents Per Year") + guides(fill=guide_legend(title="Severity"), size=10)
```

```{r fig1, fig.height=6, fig.width=15, fig.align="center"}
#print the plot in a big resolution
p
```


**3.2. Can the trend be explained by a change in accidents with pedestrians? Share the accidents with pedestrians and those without. What kind of accident is the trend in?**

We can see two different interesting conclusions from dividing the graphs. First, The severe accidents with pedestrians involved are on the rise, while the severe accidents without pedestrians involved trend doesn't changing a lot. On the other hand, We can see that in both of the semi-graphs there is a "happy parabula shape" when we look on the fatal accidents, that are on a downward trend until the big jump at 2018. In conclusion, the big change is in the severe accidents, we can see that the source of the increase is that of accidents without pedestrians.





  
###4. Accident locations 
**4.1. Draw a scatter chart for all accidents, where each accident is indicated as a small gray dot. The x-axis is the longitude and the y-axis is the latitude. Add fatal accidents as a large red dot.**

To answer this task, we can simply create a table of the streets with a total accidents columns, pedestrians-involved accidents column and their ratio column.
Later we can use ggplot to create the plot.

**4.2. Find the street (with at least 100 accidents) with the highest rate of accidents involving pedestrians. Mark this street in the blue color chart (Hint: you can use accidents on these streets and paint these dots in blue). Use the street1 field.**

To do both tasks, we can mutate using dplyr a colors column (which will help us with the legend later) and than continue building the plot.

```{r}
#create an is_pedestrian_involved column
accidents.new$pedestrian_involved =  ifelse(accidents.new$accident_type_hebrew == "פגיעה בהולך רגל","Pedestrian Involved","No Pedestrians Involved")
#create a table of pedestrians-involved accidents by streets
streets_pedestrians = accidents.new %>%  group_by(street1_hebrew) %>% summarize(total = sum(ifelse(pedestrian_involved=="Pedestrian Involved",1,0)))
#sum the total accidents on each street
streets = accidents.new %>%  group_by(street1_hebrew) %>% summarize(total = sum(X))
#merge tables
streets_merged = merge(streets, streets_pedestrians, by = "street1_hebrew")
#fix colnames
colnames(streets_merged) = c("street","accidents", "pedestrian_accidents")
#filter the below 100 total accidents
streets_merged_over_100 = filter(streets_merged, accidents>100)
#create ratio column
streets_merged_over_100$ratio = streets_merged_over_100$pedestrian_accidents/streets_merged_over_100$accidents
#find the maximum ratio street
max_ratio_road = streets_merged_over_100[which.max(streets_merged_over_100$ratio),1]
```

```{r fig2, fig.height=10, fig.width=12}
#create the plot using dplyr for building the legend
accidents %>% mutate(color = ifelse(street1_hebrew==max_ratio_road, "highest pedestrians accident ratio road", ifelse(accident_severity =="קטלנית", 'תאונה קטלנית', 'תאונה'))) %>%

ggplot(aes(x=longitude, y=latitude, size = ifelse(street1_hebrew==max_ratio_road , 2  ,ifelse(accident_severity == "קטלנית",3.5,1)) ,color=color)) + geom_point(alpha=0.6) + 
  theme_light() + theme(legend.position = "bottom", title=element_text(size=20),axis.text = element_text(size=15), legend.text = element_text(size=20)) +
  ggtitle("Accidents Across Tel Aviv") + scale_color_manual(values = c("blue","grey50","red")) +scale_size_identity() + 
  guides(colour = guide_legend(override.aes = list(size=10)))
```

We can see that the most pedestrian-involved-in-accidents street, Bugrashov Street, is not close to the major fatal accident areas (that are closer to the main roads). There are several explanations for this: first, on a street with many pedestrian accidents there are (clearly) a lot of pedestrians! Therefore, on such streets, where pedestrians cross and walk near the road, traffic will be slower and even if pedestrians get hit by a car, it will probably happen at low speed. On the other hand, it can be seen from the map that the most lethal roads are main roads (Ayalon Highways for example) where passengers travel at high speeds, and pedestrians simply do not go there.




### 5. Distribution of daily accidents

**5.1. Calculate the number of accidents per day. Does the normal approximation describe the breakdown of daily accidents? Show with a suitable graph. (Should be about 2200 entries).**

To calculate the number of accidents per day, we can use again the group_by() and summerize() functions from the ggplot. This time, we will aggregate our data by the date which is represented by three columns: accident_year, accident_month and accident_day.

Later on, we will use the ggoplot library to draw a histogram, and compare it to the number of accidents per day density and to the normal density with same expectation and sd.

```{r}
#grouping the data by the date
per_day = accidents.new %>% group_by(accident_year, accident_month, accident_day, day_in_week_hebrew) %>% summarize(total = sum(X))

# Density plots with semi-transparent fill
ggplot(per_day, aes(x=total))+
  #histogram
  geom_histogram(aes(x=total, y=..density.., fill="Histogram"),colour="grey30", bins=19) + 
  #density of the distribution
  geom_density(aes(fill="Simulated Density"), alpha=.5, color = "navyblue") + 
  #normal curve
  stat_function(aes(color = "Normal Curve"), fun = dnorm, args = list(mean = mean(per_day$total), sd = sd(per_day$total)), size=1.2) +
  #some designing
  ggtitle("Number of car accidents a day in Tel-Aviv between 2013 - 2018",subtitle = "Density, Histogram and Normal Dist.") + 
  coord_cartesian(xlim = c(-2,37)) + scale_fill_manual(values = c("grey80","navy")) + theme_minimal() + labs(fill = "Simulated", colour="Normal Distribution")
``` 

By this graph we can say that the number of accidents per day distribution is close to normal, but not perfectly normal. The bell curve that suits the normal distibution can be seen clearly, but the tails are not equal and we have a strong right tail and almost no tail at all to the left.

We can also check with a QQ plot and get similar results:

```{r}
#qqplot
qqnorm(y=per_day$total)
#qqline
qqline(per_day$total)

```

**5.2. Now only isolate Sundays. For this distribution, write a code that finds the distance between the quarters (Inter quantile range) without using the quantile function or external packages.**

We can isolate sundays by filter from our per day table only the sundays, using filter() function by dplyr.
To calcualte the interquantile range, we need to subtract the first quartile (25th percentile) from the third quartile(75th precentile). By definition, the first quartile of X are the values of X that quarter of the values are lower from it, and the third quartile of X is the value of X that qaurter of the values are higher from it. So, all we have to do is to sort the values of sundays by increasing order of accidents per day (using dplyr again) and then, to take the values in the relevant places and subtract between them.

```{r}
#filter by sundays.
per_sunday = per_day %>% filter(day_in_week_hebrew=="ראשון")

interquantile_range = function(x){
  x = as.matrix(x)
  #calculate the distance between 3rd and 1st quantiles
   sort(x)[length(x)*0.75] - sort(x)[length(x)*0.25]
}
interquantile_range(per_sunday$total)

```


We get that the interquantile range of the number of car accidents on Sundays is: 8.


####5.3.  use Monte Carlo to estimate the probability that the number of accidents on Friday will be greater than the number of accidents on Sunday. Each time, one sample was sampled from the observed distributions of several accidents on Sunday and once from the distribution of several accidents on Friday.

**5.3.1. Write a function that receives a number of repetitions and estimates the probability and the standard deviation.**
```{r}

#filter the accident of friday and arrange them
per_friday = per_day %>% filter(day_in_week_hebrew=="שישי") %>% arrange(total)

#this function get a number of reps and for each iteration samples
#from fridays and sundays accidents and check what is the probabillity that there
#are more accidents on friday than on sunday
#int B - number of reps
#return list with sd and probabillity estimator.

mc_friday_vs_sunday = function(B){
  
  #helper function to calculate a boolean vector
  #of the friday "wins" aginst sunday
  result_vector_helper = function(b){
  #empty vector
  result_vec = c()
  #for B times check who "wins" and add to the vector
  for (i in 1:b){
    result_vec = c(result_vec ,sample(per_sunday$total, 1) < sample(per_friday$total, 1))}
    return(result_vec)
  }
  p.hats = c()
  #calculate the mean of the monte carlo experiment
  for(i in 1:100){
    result_vec = result_vector_helper(B)
    p.hats = c(p.hats, mean(result_vec))
    #calculate sd/10 because it's an sd of the average, var(x.gag) = (1/n)*var(x), and sd is the root.
  }
  result_list = list("p.hat" = mean(p.hats), "sd" = sd(p.hats))

  return(result_list)
}
```
**5.3.2. Report the results you received**




```{r pr}
#the result list
estimator_list = mc_friday_vs_sunday(10000)
#the probabillity estimator
mu = estimator_list$p.hat
#the standart deviation
s = estimator_list$sd

estimator_list
```

Since we did an average of 100 Monte Carlo experiments, we get a more accurate estimator for p.hat (the probabillity that the number of accidents in Friday will be greater than the average on Sunday).
Moreover, since that estimator is an average of a random variable, it's variance is (1/n)*Var(X), therefore, if we calculate an sd of a vector of all our monte carlo resultes, it will be 1/100 of the estimator we would get in a single monte carlo experiment. So, we get an estimator of 1.64 with a standart deviation of 0.003 which is ver low. That how we can improve the accuracy of our probabillity estimator.

We can see that after we ran our Monte-Carlo experiment, the probabillity that the number of accidents on friday will be higher than the number of accidents from sunday is 0.164, and the standart deviation is of 0.37


**5.4. (10) A researcher is planning a test to test the hypothesis that the incidence of accidents on Sundays is higher than on Fridays (a one-sided test). He was planning a sample of 9 Sunday and 9 Fridays. Suppose that he rejects the 0 hypothesis if a p value is less than 0.05.**

We will use Monte Carlo to gauge the power of the test, that means that he will reject the 0 hypothesis. We will use B = 200 repetitions, and consider the standard deviation of our estimate. This time, we can write everything in one row by using replicate() and t.test() functions. 


```{r}
#create the t estimator
t_estimator = replicate(200, t.test(sample(per_sunday$total, 9), sample(per_friday$total, 9), alternative = "greater")$p.value<0.05)
#print the results
print(paste0("Power estimator:" ,mean(t_estimator)))
print(paste0("Standart Deviation:" ,sd(t_estimator)))
```

We can see that the Powe estimator is close to 0.83, and that the sd is around 0.367.

###6. Open Question

**6.1. Look for data that we have not addressed until now, something the Barber is a new and interesting story. You can draw a graph or view a table. The hand will be given according to the matching of the use of the data to the question you have examined.**


Along I was working on the data, I had in my mind two questions that i had to check. At first, i wanted to know if over the last five years, there was a change in the precentage of the different accidents type. To do so, I had to group by the data by years and accident types. The next step was to create a ratio from the numbers (since we are intrested in the precentage of each type in each year). The final step was showing the result using ggplot.

```{r fig3, fig.width=12, fig.height=10}
#grouping by types
types = accidents.new %>% group_by(accident_year, accident_type_hebrew) %>% summarise(total = sum(X)) %>% filter(total>50)
#create the yearly ratio from the counting of accidents
for (i in 2013:2018){
types[which(types$accident_year==i),3] = types[which(types$accident_year==i),3]/sum(types$total[types$accident_year==i])
}
#show the plot
ggplot(data = types, aes(x=accident_year, y=total, colour=accident_type_hebrew)) + geom_line(size=2) + ggtitle("Accident types precent along the years") + xlab("Years") + ylab("Yearly type rate")
```
The most signifact change over the pas 5 years was in Side-By_Side crushes, that became the second most common type of accidents after the Front-To-Back crushes, and passed Back-To-Front crushes, Pedestrian-involved accidents, and Slip accidents.


In addition, we can try guess what's define the side-by-side accident that is getting more and more common each year.
```{r}

side_accidents = accidents.new %>% filter(accident_type_hebrew == "התנגשות צד בצד") 


side_accidents %>% group_by(day_night_hebrew) %>% summarise(total = sum(X)) %>% 
  ggplot(aes(x = "", y = total, fill = day_night_hebrew)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0) + theme_void() + guides(fill=guide_legend(title="Legend"))

side_accidents %>% group_by(road_width_hebrew) %>% summarise(total = sum(X)) %>% filter(str_detect(road_width_hebrew,"")) %>%
  ggplot(aes(x = "", y = total, fill = road_width_hebrew)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0) + theme_void() + guides(fill=guide_legend(title="Legend"))

side_accidents %>% group_by(road_surface_hebrew) %>% summarise(total = sum(X)) %>%  filter(!str_detect(road_surface_hebrew,"לא ידוע")) %>%
  ggplot(aes(x = "", y = total, fill = road_surface_hebrew)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0) + theme_void() + guides(fill=guide_legend(title="Legend"))


side_accidents %>% group_by(weather_hebrew) %>% summarise(total = sum(X)) %>%  filter(!str_detect(weather_hebrew,"לא ידוע")) %>%
  ggplot(aes(x = "", y = total, fill = weather_hebrew)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0) + theme_void() + guides(fill=guide_legend(title="Legend"))

```
We can see that around quarter of the side-by-side accidents are happening during the day, which is more then the day and night relation which is around 2.6 (that means that if we take the overall night accidents and split by the total number of accident we will get 2.6). Moreover, we can see that the rain presentage accident is a bit higher than the total rain/total relation, and same as the wet road vs. total accidents relation.


The next question that i want to ask myself, is if there is a significant difference between the day and the night accidents, And we are going to check it with few different parameters.
I chose this question because day vs. night is the only parameter with no missing values or "other" values, and it will be interesting to check wether there is a difference between these two groups.
First, let's check how many night/day accidents we have:
```{r, fig.width=15}
#check how many values from each
as.data.frame(table(accidents.new$day_night_hebrew))
```

We can see that there are way more day accidents than night accidents. Clearly this has a thing with the fact that there are more vehicles over night time on the road.

Now, lets see if there was a difference between the precentage of night and day accidents over the 5 past years:
```{r}
#magic numbers constants
DAY_ACC = 24015
NIGHT_ACC = 8722

#create the yearly count table, we will use it
yearly = spread(accidents.new %>% group_by(accident_year) %>% summarise(total = sum(X)),key=accident_year, value=total)
#grouping by day/night and year
day_night_history = accidents.new %>% group_by(day_night_hebrew, accident_year) %>% summarise(total = sum(X))

#creating a yearly rate for each type
for(i in 1:nrow(day_night_history)){
  day_night_history[i, "yearly"] = yearly[as.character(day_night_history[i, "accident_year"])]
}


#add the rate
day_night_history$rate = day_night_history$total/day_night_history$yearly
#show the plot
ggplot(data = day_night_history, aes(x=accident_year, y=rate, color = day_night_hebrew)) + geom_line() + ggtitle("Changing in Day/Night Accidents Precent") + xlab("Year") + ylab("Yearly Precent")


```

We can see that there is not much of a difference between the years, and along all the last years, the precentage of night accidents was very low among all the accidents in Tel Aviv.

Now, Let's check the involvment of pedestrians:
Again, because of the difference between the numbers, we will first count the pedestrians involvement in accidents during the day and night, and later on split by number of accidents at day and at night.
```{r, fig5, fig.width=10, fig.height=10}
#create grouping by the day vs the night
day_night_pedes = accidents.new %>% group_by(day_night_hebrew, pedestrian_involved) %>% summarise(total = sum(X))
day_night_pedes$total = ifelse(day_night_pedes$day_night_hebrew=="יום",day_night_pedes$total/DAY_ACC, day_night_pedes$total/NIGHT_ACC)
#plot
ggplot(data = day_night_pedes, aes(x=pedestrian_involved, y=total, fill=pedestrian_involved)) + geom_bar(stat = "identity")  + xlab("Year") + ylab("Pedestrian Involvment precentage")+facet_wrap(.~day_night_hebrew) + geom_text(aes(label=round(total,3)), vjust=2, color="white",
            position = position_dodge(1), size=4 ) + theme(axis.text.x = element_text(angle=45, vjust = 0.5))
```

We can see that there is no much difference between the night and the day on the pedestrian involvement precentage.

As we have seen before, along time there was a change in the precentage of the different accident types. But what happend when we split the types to day accidents and night accident ? Is there a difference between the split?

```{r, fig.width=12, fig.height=7}
day_night_types = accidents.new %>% group_by(day_night_hebrew, accident_type_hebrew) %>% summarise(total = sum(X))
day_night_types$total = ifelse(day_night_types$day_night_hebrew=="יום",day_night_types$total/DAY_ACC, day_night_types$total/NIGHT_ACC)

ggplot(data = day_night_types, aes(x=accident_type_hebrew, y=total, group = day_night_hebrew, fill=accident_type_hebrew)) + geom_bar(stat = "identity") + facet_wrap(.~day_night_hebrew) + theme(axis.text.x = element_text(angle=90, size=10)) + xlab("Accident Types") + ylab("Precentage of DayTime") + guides(fill=guide_legend(title="Accident Type"))
```

It is interesting to see that while the second most common accident type during the day is Side-To-Side accident, at night, the second most common (and not far from the first) is Front-To-Side accident. I think about two reasonable explaintions: First, the lack of visiabllithy at night time can cause a driver not to notice his surroundings. Second, I believe that at nights, drunk drivers and people who think that the road is empty, are trying to "steal" the red light, and jump inside crossroads, even when they must stop, and therefor someone who has green light is is crushing them or get crushed by them.

In Conclusion, i would say that most of the difference between the days accidents and the nights accidents, is coming from the type of the accident, that can be cause from various reasons.

**תודה רבה, היה קורס מעולה**